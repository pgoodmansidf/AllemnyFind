"""Add table metadata columns

Revision ID: 638371deba43
Revises: 7b6209b2899f
Create Date: 2025-08-03 12:42:39.549941

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '638371deba43'
down_revision: Union[str, Sequence[str], None] = '7b6209b2899f'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_search_sessions_id'), table_name='search_sessions')
    op.drop_index(op.f('ix_search_sessions_user_id'), table_name='search_sessions')
    op.drop_table('search_sessions')
    op.drop_index(op.f('ix_search_queries_created_at'), table_name='search_queries')
    op.drop_index(op.f('ix_search_queries_id'), table_name='search_queries')
    op.drop_index(op.f('ix_search_queries_user_id'), table_name='search_queries')
    op.drop_table('search_queries')
    op.add_column('document_chunks', sa.Column('chunk_type', sa.String(length=50), nullable=True))
    op.add_column('document_chunks', sa.Column('is_table', sa.Boolean(), nullable=True))
    op.add_column('document_chunks', sa.Column('table_name', sa.String(length=200), nullable=True))
    op.add_column('document_chunks', sa.Column('table_headers', postgresql.ARRAY(sa.String()), nullable=True))
    op.add_column('document_chunks', sa.Column('table_summary', sa.Text(), nullable=True))
    op.add_column('document_chunks', sa.Column('section_hierarchy', postgresql.ARRAY(sa.String()), nullable=True))
    op.alter_column('document_chunks', 'embedding',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=1536),
               existing_nullable=True)
    op.drop_index(op.f('idx_document_chunks_document_id'), table_name='document_chunks')
    op.drop_index(op.f('idx_document_chunks_embedding_model'), table_name='document_chunks')
    op.create_index('idx_chunks_doc_embedding', 'document_chunks', ['document_id', 'embedding_model'], unique=False)
    op.create_index('idx_chunks_table', 'document_chunks', ['is_table'], unique=False)
    op.create_index('idx_chunks_type', 'document_chunks', ['chunk_type'], unique=False)
    op.drop_column('document_chunks', 'end_char')
    op.drop_column('document_chunks', 'section_title')
    op.drop_column('document_chunks', 'subsection_title')
    op.drop_column('document_chunks', 'start_char')
    op.add_column('documents', sa.Column('title', sa.String(length=500), nullable=True))
    op.add_column('documents', sa.Column('author', sa.String(length=200), nullable=True))
    op.add_column('documents', sa.Column('creation_date', sa.DateTime(timezone=True), nullable=True))
    op.add_column('documents', sa.Column('modification_date', sa.DateTime(timezone=True), nullable=True))
    op.add_column('documents', sa.Column('file_data', sa.LargeBinary(), nullable=True))
    op.add_column('documents', sa.Column('storage_path', sa.String(length=500), nullable=True))
    op.add_column('documents', sa.Column('storage_type', sa.String(length=20), nullable=True))
    op.add_column('documents', sa.Column('has_tables', sa.Boolean(), nullable=True))
    op.add_column('documents', sa.Column('table_count', sa.Integer(), nullable=True))
    op.add_column('documents', sa.Column('table_metadata', sa.JSON(), nullable=True))
    op.add_column('documents', sa.Column('main_tag', sa.String(length=100), nullable=True))
    op.drop_index(op.f('ix_documents_collection_name'), table_name='documents')
    op.create_index(op.f('ix_documents_main_tag'), 'documents', ['main_tag'], unique=False)
    op.drop_column('documents', 'status')
    op.drop_column('documents', 'groq_response')
    op.drop_column('documents', 'collection_name')
    op.drop_column('documents', 'is_public')
    op.alter_column('users', 'hashed_password',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=200),
               existing_nullable=False)
    op.drop_constraint(op.f('users_api_key_key'), 'users', type_='unique')
    op.drop_column('users', 'updated_at')
    op.drop_column('users', 'api_key')
    op.drop_column('users', 'preferences')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('users', sa.Column('preferences', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('api_key', sa.VARCHAR(length=64), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.create_unique_constraint(op.f('users_api_key_key'), 'users', ['api_key'], postgresql_nulls_not_distinct=False)
    op.alter_column('users', 'hashed_password',
               existing_type=sa.String(length=200),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.add_column('documents', sa.Column('is_public', sa.BOOLEAN(), autoincrement=False, nullable=True))
    op.add_column('documents', sa.Column('collection_name', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('documents', sa.Column('groq_response', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('documents', sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_documents_main_tag'), table_name='documents')
    op.create_index(op.f('ix_documents_collection_name'), 'documents', ['collection_name'], unique=False)
    op.drop_column('documents', 'main_tag')
    op.drop_column('documents', 'table_metadata')
    op.drop_column('documents', 'table_count')
    op.drop_column('documents', 'has_tables')
    op.drop_column('documents', 'storage_type')
    op.drop_column('documents', 'storage_path')
    op.drop_column('documents', 'file_data')
    op.drop_column('documents', 'modification_date')
    op.drop_column('documents', 'creation_date')
    op.drop_column('documents', 'author')
    op.drop_column('documents', 'title')
    op.add_column('document_chunks', sa.Column('start_char', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('document_chunks', sa.Column('subsection_title', sa.VARCHAR(length=200), autoincrement=False, nullable=True))
    op.add_column('document_chunks', sa.Column('section_title', sa.VARCHAR(length=200), autoincrement=False, nullable=True))
    op.add_column('document_chunks', sa.Column('end_char', sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_index('idx_chunks_type', table_name='document_chunks')
    op.drop_index('idx_chunks_table', table_name='document_chunks')
    op.drop_index('idx_chunks_doc_embedding', table_name='document_chunks')
    op.create_index(op.f('idx_document_chunks_embedding_model'), 'document_chunks', ['embedding_model'], unique=False)
    op.create_index(op.f('idx_document_chunks_document_id'), 'document_chunks', ['document_id'], unique=False)
    op.alter_column('document_chunks', 'embedding',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=1536),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_nullable=True)
    op.drop_column('document_chunks', 'section_hierarchy')
    op.drop_column('document_chunks', 'table_summary')
    op.drop_column('document_chunks', 'table_headers')
    op.drop_column('document_chunks', 'table_name')
    op.drop_column('document_chunks', 'is_table')
    op.drop_column('document_chunks', 'chunk_type')
    op.create_table('search_queries',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('query_text', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('response_content', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('include_online', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('search_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('processing_time', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('success', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('citations_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('search_metadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('agent_stages', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('search_queries_pkey'))
    )
    op.create_index(op.f('ix_search_queries_user_id'), 'search_queries', ['user_id'], unique=False)
    op.create_index(op.f('ix_search_queries_id'), 'search_queries', ['id'], unique=False)
    op.create_index(op.f('ix_search_queries_created_at'), 'search_queries', ['created_at'], unique=False)
    op.create_table('search_sessions',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('session_name', sa.VARCHAR(length=200), autoincrement=False, nullable=True),
    sa.Column('total_queries', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('successful_queries', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('average_response_time', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('last_activity', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('search_sessions_pkey'))
    )
    op.create_index(op.f('ix_search_sessions_user_id'), 'search_sessions', ['user_id'], unique=False)
    op.create_index(op.f('ix_search_sessions_id'), 'search_sessions', ['id'], unique=False)
    # ### end Alembic commands ###
